{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "with open('../featureEng.csv', 'r') as F:\n",
    "    df = F.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age,sex,resting bps,cholesterol,fasting blood sugar,max heart rate,exercise angina,oldpeak,target,chest pain type_1,chest pain type_2,chest pain type_3,resting ecg_1,resting ecg_2,ST slope_1,ST slope_2,ST slope_3\n",
      "0.2448979591836734,1,0.7000000000000001,0.47927031509121065,0,0.7887323943661971,0,0.0,0,False,True,False,False,False,True,False,False\n",
      "0.4285714285714285,0,0.8,0.2985074626865672,0,0.6760563380281691,0,1.0,1,False,False,True,False,False,False,True,False\n",
      "0.18367346938775508,1,0.65,0.46932006633499174,0,0.2676056338028169,0,0.0,0,False,True,False,True,False,True,False,False\n",
      "0.40816326530612246,0,0.6900000000000001,0.3548922056384743,0,0.3380281690140845,1,1.5,1,False,False,False,False,False,False,True,False\n",
      "0.5306122448979591,1,0.75,0.32338308457711445,0,0.43661971830985913,0,0.0,0,False,False,True,False,False,True,False,False\n",
      "0.22448979591836726,1,0.6,0.5621890547263682,0,0.7746478873239436,0,0.0,0,False,False,True,False,False,True,False,False\n",
      "0.346938775510204,0,0.65,0.3930348\n"
     ]
    }
   ],
   "source": [
    "type(df)\n",
    "print(df[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143791"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n",
      "Transformers version: 4.48.2\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipel' from 'transformers' (/opt/anaconda3/envs/hf_env/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pipel' from 'transformers' (/opt/anaconda3/envs/hf_env/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "X_train = [\"I love you\", \"I hate you\", \"I dont know\", \"I'm using Hugging Face\", \"I'm doing some research work!\"] # a list of input texts\n",
    "res = classifier(X_train)\n",
    "print(res)\n",
    "\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\") # `pt` means PyTorch format\n",
    "print(batch)\n",
    "\n",
    "# inference in PyTorch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch) # unpack the batch into the model, beccause it is a dictionary\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1) # it should get the same score as we got from the pipeline\n",
    "    labels = torch.argmax(predictions, dim=1)\n",
    "    print(labels)\n",
    "    # logits = model(**batch).logits\n",
    "    # predictions = F.softmax(logits, dim=-1)\n",
    "    # print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
